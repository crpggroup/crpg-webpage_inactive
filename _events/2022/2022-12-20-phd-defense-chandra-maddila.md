---
layout: event
title: "PhD Thesis Defense: Recommender Systems for DevOps"
categories: [events, defenses]
start: "15:00"
end: "17:00"
speaker: Chandra Maddila
where: Aula
---

_Note: The defense will start at 15:00 sharp. There will be **no** laymen's presentation._

**Thesis Summary**

The software development life cycle (SDLC) for a developer has increased in complexity and scale. With the advent of DevOps processes, the gap between development and operations teams reduced significantly. Developers are now expected to perform different roles from coding to operational support in the new model of software development. This shift demands the evolution and improvement of software development practices and deliver products at a faster pace than organizations using traditional software development and infrastructure management processes. As a consequence, the demand for more intelligent and context sensitive DevOps tools and services that help developers increase their efficiency is increasing. A lot of research went into developing recommenders for DevOps, by leveraging the advancements made by the recommender system community. However, a lot of existing tools still work in ‘silos’ and does not take into account a holistic view DevOps processes and the data generated at phase of the DevOps lifecycle while making recommendations.

By contrast, in this thesis, we propose a unified framework we developed to develop recommenders for DevOps: perform data collection, building the models, deploying them, and evaluating the effectiveness of such recommenders in large-scale cloud development environments quickly and efficiently. We study the effect of such recommenders on the DevOps processes by performing empirical research and mixed method approaches (qualitative and quantitative analyses) on each of the deployed recommenders to better understand the productivity gains and the impact created by them.
Our results show that developers benefit greatly from smart recommenders such as Nudge, ConE, Orca, and MyNalanda. We also show, through rigorous experiments, technical action research methods, and empirical analyses that these recommenders provide as much as 65% gains in terms of change progression and 73% accuracy for root causing the service incidents automatically. We also conduct large scale surveys and interviews to support our empirical analysis and quantitative results. Our unified data framework and the platform we developed for building these recommenders is generic enough and encourages reusability of vital functions of such recommenders systems, such as data collection, model training, inference, deployment, and evaluation.
xiii